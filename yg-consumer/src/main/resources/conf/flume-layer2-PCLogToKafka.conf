layer2-253.sources = source_184
layer2-253.channels = pc_184
layer2-253.sinks = kafka_179

# Configure source: source_184 -> pc_184
layer2-253.sources.source_184.channels = pc_184
layer2-253.sources.source_184.type = avro
layer2-253.sources.source_184.bind = 192.168.211.253
layer2-253.sources.source_184.port = 44446
layer2-253.sources.source_184.threads = 2

# Configure channel(/data4)
# Configure Ad channel: pc_184 ->kafka_179
layer2-253.channels.pc_184.type = file
layer2-253.channels.pc_184.checkpointDir = /data/flume/channels/yougou_pc/checkpoint
layer2-253.channels.pc_184.useDualCheckpoints = true
layer2-253.channels.pc_184.backupCheckpointDir = /data/flume/channels/yougou_pc/backup
layer2-253.channels.pc_184.dataDirs = /data/flume/channels/yougou_pc/data
layer2-253.channels.pc_184.transactionCapacity = 100000
layer2-253.channels.pc_184.capacity = 500000
layer2-253.channels.pc_184.checkpointInterval = 60000
layer2-253.channels.pc_184.keep-alive = 5
layer2-253.channels.pc_184.maxFileSize = 5368709120

# Configure sinks: KafkaSink
#layer2-253.sinks.kafka_179.type = org.yougou.flume.sink.KafkaSink
layer2-253.sinks.kafka_179.type = org.open.flume.sink.KafkaSink
layer2-253.sinks.kafka_179.preprocessor = org.open.flume.impl.SimpleMessagePreprocessor
layer2-253.sinks.kafka_179.channel = pc_184
layer2-253.sinks.kafka_179.metadata.broker.list = slave1:9092
layer2-253.sinks.kafka_179.topic = flume_pc
layer2-253.sinks.kafka_179.serializer.class = kafka.serializer.StringEncoder
layer2-253.sinks.kafka_179.producer.type = async
layer2-253.sinks.kafka_179.message.send.max.retries = 3
layer2-253.sinks.kafka_179.client.id = flume_PC_2_1
layer2-253.sinks.kafka_179.event.decoder.count = 4
layer2-253.sinks.kafka_179.output.stat.event.batch.size = 2500
layer2-253.sinks.kafka_179.event.decoder.queue.size = 5000